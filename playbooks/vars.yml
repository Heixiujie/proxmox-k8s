# LXC template to use for your containers. 
# To find the newest release: $pveam available | grep ubuntu | awk '{print $2}'
lxc_template: 'ubuntu-20.04-standard_20.04-1_amd64.tar.gz'

# Storage Volume where your template will be stored
template_storage: 'local'

# Pool for your compute resources to be placed in
k8s_resource_pool: "Kubernetes"

# Path to the SSH Public Key on your Proxmox Server to be used with your compute resources
k8s_ssh_key: "/root/.ssh/id_rsa.pub"
# cp local rsa.pub key to pve host, so it can be added when containers are provisioned  
# ubt@ubt-stg:~/.ssh$ scp id_rsa.client.pub root@pve:/root/.ssh/id_rsa.client.pub
k8s_ansible_client_ssh_key: "/root/.ssh/id_rsa.client.pub"

# k8s install
k8s_gpg_key_url: "https://packages.cloud.google.com/apt/doc/apt-key.gpg"
k8s_sources_file: "/etc/apt/sources.list.d/kubernetes.list"
k8s_apt_kube_key: "deb https://apt.kubernetes.io/ kubernetes-xenial main"

pod_network: --pod-network-cidr=10.244.0.0/16
apiserver_advertise_address: --apiserver-advertise-address=192.168.1.120 
dns_domain: --service-dns-domain=k8s.local
preflight_options: --ignore-preflight-errors=all

kube_file_path: "/home/kube_master/.kube"
kube_config_path: "/home/kube_master/.kube/config"
kube_admin_file: "/etc/kubernetes/admin.conf"

# k8s plugins 
helm_url: "https://git.io/get_helm.sh"
flannel_url: "https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml"
nvidia_device_plugin: "https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/1.0.0-beta3/nvidia-device-plugin.yml"


# root pw
root_password: 'k8s#pw#1234'

# VM IDs
k8s_node0_id: '120'
k8s_node1_id: '121'
k8s_node2_id: '122'
k8s_node3_id: '123'

# Hostnames
k8s_node0_hn: "k8s-n00"
k8s_node1_hn: "k8s-n01"
k8s_node2_hn: "k8s-n02"
k8s_node3_hn: "k8s-n03"

# Number of CPUs
k8s_node0_cpu: "1"
k8s_node1_cpu: "4"
k8s_node2_cpu: "4"
k8s_node3_cpu: "4"

# Amount of memory expressed in megabytes
k8s_node0_mem: "4096"
k8s_node1_mem: "31744"
k8s_node2_mem: "31744"
k8s_node3_mem: "31744"

# Disk Sizes
k8s_node0_ds: "40G"
k8s_node1_ds: "100G"
k8s_node2_ds: "100G"
k8s_node3_ds: "100G"


# IP Addresses
k8s_node0_ip: "192.168.1.120"
k8s_node1_ip: "192.168.1.121"
k8s_node2_ip: "192.168.1.122"
k8s_node3_ip: "192.168.1.123"

# Mac addresses # Use mac if static ip assignment via dhcp is planned
k8s_node0_mac: "2A:B1:18:65:25:3A"
k8s_node1_mac: "BA:BC:17:91:FE:4E"
k8s_node2_mac: "CA:93:34:96:8B:02"
k8s_node3_mac: "1A:23:16:FC:25:A1"

# Subnet Sizes
k8s_node0_sn: "/24"
k8s_node1_sn: "/24"
k8s_node2_sn: "/24"
k8s_node3_sn: "/24"

# Network Gateway
k8s_node0_gw: "192.168.1.1"
k8s_node1_gw: "192.168.1.1"
k8s_node2_gw: "192.168.1.1"
k8s_node3_gw: "192.168.1.1"

# DNS Servers
k8s_node0_ns: "192.168.1.1"
k8s_node1_ns: "192.168.1.1"
k8s_node2_ns: "192.168.1.1"
k8s_node3_ns: "192.168.1.1"

# Search Domains
k8s_node0_sd: "fritz.box"
k8s_node1_sd: "fritz.box"
k8s_node2_sd: "fritz.box"
k8s_node3_sd: "fritz.box"

# Network Bridges
k8s_node0_bridge: "vmbr0"
k8s_node1_bridge: "vmbr0"
k8s_node2_bridge: "vmbr0"
k8s_node3_bridge: "vmbr0"

# Storage volumes for rootfs [ wd80 (hdd 8TB) , local-lvm (ssd 2TB) ]
k8s_node0_stg: "local-lvm"
k8s_node1_stg: "local-lvm"
k8s_node2_stg: "local-lvm"
k8s_node3_stg: "local-lvm"

# Optional storage mount 
k8s_lab_disk_share : "/mnt/pve/wd80/private/lab/share"
k8s_lab_disk_dataset : "/mnt/pve/wd80/private/lab/dataset"
k8s_node0_disk_space : "/mnt/pve/wd80/private/lab/k8s-n00"
k8s_node1_disk_space : "/mnt/pve/wd80/private/lab/k8s-n01"
k8s_node2_disk_space : "/mnt/pve/wd80/private/lab/k8s-n02"
k8s_node3_disk_space : "/mnt/pve/wd80/private/lab/k8s-n03"

# Insecured docker registries
insecured_docker_registries: '["your_registry_url:port","192.168.1.3:38095"]'
